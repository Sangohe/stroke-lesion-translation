{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-24 19:31:39.598134: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-07-24 19:31:41.157571: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nibabel as nib\n",
    "import tensorflow as tf\n",
    "from tqdm.notebook import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import sys\n",
    "import shutil\n",
    "from pathlib import Path\n",
    "from typing import Union, List\n",
    "\n",
    "sys.path.append(\"..\")\n",
    "\n",
    "from plotting import window_image\n",
    "from models.pix2pix import Generator, Discriminator\n",
    "from run_management import get_path_of_directory_with_id\n",
    "from preprocessing import min_max_normalization, ct_denormalization\n",
    "\n",
    "tf.get_logger().setLevel(\"ERROR\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ones_normalization(x):\n",
    "    return (x - 0.5) * 2.0\n",
    "\n",
    "\n",
    "def ones_back_normalization(x):\n",
    "    return (x / 2.0) + 0.5\n",
    "\n",
    "\n",
    "def min_max_back_normalization(x, x_min, x_max):\n",
    "    return (x * (x_max - x_min)) + x_min\n",
    "\n",
    "\n",
    "def compute_metrics(real_image, fake_image):\n",
    "    return {\n",
    "        \"psnr\": tf.image.psnr(real_image, fake_image, max_val=1.0).numpy(),\n",
    "        \"ssim\": tf.image.ssim(real_image, fake_image, max_val=1.0).numpy(),\n",
    "        \"ssim_multiscale\": tf.image.ssim_multiscale(\n",
    "            real_image, fake_image, max_val=1.0\n",
    "        ).numpy(),\n",
    "    }\n",
    "\n",
    "\n",
    "def load_models(weights_dir, out_channels, out_activation):\n",
    "    generator = Generator(out_channels, out_activation)\n",
    "    discriminator = Discriminator()\n",
    "\n",
    "    generator_optimizer = tf.keras.optimizers.Adam(1e-5, beta_1=0.5)\n",
    "    discriminator_optimizer = tf.keras.optimizers.Adam(1e-5, beta_1=0.5)\n",
    "\n",
    "    ckpt = tf.train.Checkpoint(\n",
    "        generator_optimizer=generator_optimizer,\n",
    "        discriminator_optimizer=discriminator_optimizer,\n",
    "        generator=generator,\n",
    "        discriminator=discriminator,\n",
    "    )\n",
    "    ckpt.restore(tf.train.latest_checkpoint(weights_dir))\n",
    "    return generator, discriminator\n",
    "\n",
    "\n",
    "def save_translations(save_dir: Union[str, Path], generator: tf.keras.Model):\n",
    "    save_dir = Path(save_dir) if isinstance(save_dir, str) else save_dir\n",
    "    figures_dir = save_dir / \"figures\"\n",
    "    figures_dir.mkdir(exist_ok=True)\n",
    "    niftis_dir = save_dir / \"niftis\"\n",
    "    niftis_dir.mkdir(exist_ok=True)\n",
    "\n",
    "    examples_dict = {\n",
    "        \"train_026\": 45,\n",
    "        \"train_035\": 45,\n",
    "        \"train_044\": 99,\n",
    "        \"train_058\": 104,\n",
    "        \"test_022\": 69,\n",
    "        \"test_037\": 10\n",
    "    }\n",
    "    for i, (patient_id, lesion_idx) in enumerate(examples_dict.items()):\n",
    "        fig, axs = plt.subplots(figsize=(20, 20))\n",
    "        examples_dir = Path().absolute().parent / \"examples\"\n",
    "        adc_path = examples_dir / f\"{patient_id}/{patient_id}_adc.nii.gz\"\n",
    "        ncct_path = examples_dir / f\"{patient_id}/{patient_id}_ncct.nii.gz\"\n",
    "        mask_path = examples_dir / f\"{patient_id}/masks/{patient_id}_r1_mask.nii.gz\"\n",
    "\n",
    "        ncct = nib.load(ncct_path)\n",
    "        ncct_arr = ncct.get_fdata()\n",
    "        ncct_arr_win = window_image(ncct_arr, 40, 80)\n",
    "        ncct_min, ncct_max = np.min(ncct_arr), np.max(ncct_arr)\n",
    "        ncct_arr = min_max_normalization(ncct_arr)\n",
    "        ncct_arr_res = tf.image.resize(ncct_arr, [256, 256]).numpy()\n",
    "        ncct_arr_win = min_max_normalization(ncct_arr_win)\n",
    "        ncct_arr_win_res = tf.image.resize(ncct_arr_win, [256, 256]).numpy()\n",
    "\n",
    "        adc = nib.load(adc_path)\n",
    "        adc_arr = adc.get_fdata()\n",
    "        adc_min, adc_max = np.min(adc_arr), np.max(adc_arr)\n",
    "        adc_arr = min_max_normalization(adc_arr)\n",
    "        adc_arr_res = tf.image.resize(adc_arr, [256, 256]).numpy()\n",
    "\n",
    "        # Compute the fake image.\n",
    "        adc_fake_arr = generator.predict(\n",
    "            ncct_arr_res.transpose(2, 0, 1)[..., np.newaxis], verbose=0\n",
    "        )\n",
    "        adc_fake_arr = adc_fake_arr.transpose(1, 2, 0, 3)[..., 0]\n",
    "\n",
    "        # Create the plot.\n",
    "        idxs = np.array([lesion_idx + (i * 6) for i in range(-1, 2)])\n",
    "        metrics_slices = []\n",
    "        ncct_slices, adc_fake_slices, adc_slices = [], [], []\n",
    "        for idx in idxs:\n",
    "            ncct_slices.append(np.rot90(ncct_arr_win_res[..., idx]))\n",
    "            adc_fake_slices.append(np.rot90(adc_fake_arr[..., idx]))\n",
    "            adc_slices.append(np.rot90(adc_arr_res[..., idx]))\n",
    "            metrics = compute_metrics(\n",
    "                adc_arr_res[..., idx : idx + 1], adc_fake_arr[..., idx : idx + 1]\n",
    "            )\n",
    "            metrics_slices.append(\n",
    "                \"PSNR: {:.3f}, SSIM: {:.3f}\".format(metrics[\"psnr\"], metrics[\"ssim\"])\n",
    "            )\n",
    "        ncct_plot = np.vstack(ncct_slices)\n",
    "        adc_fake_plot = np.vstack(adc_fake_slices)\n",
    "        adc_plot = np.vstack(adc_slices)\n",
    "        final_plot = np.hstack([ncct_plot, adc_fake_plot, adc_plot])\n",
    "        axs.imshow(final_plot, cmap=\"gray\")\n",
    "        axs.annotate(\n",
    "            \"NCCT\", (128, 25), ha=\"center\", va=\"center\", fontsize=32, color=\"white\"\n",
    "        )\n",
    "        axs.annotate(\n",
    "            \"ADC$_{fake}$\",\n",
    "            (128 + 256 * 1, 25),\n",
    "            ha=\"center\",\n",
    "            va=\"center\",\n",
    "            fontsize=32,\n",
    "            color=\"white\",\n",
    "        )\n",
    "        axs.annotate(\n",
    "            \"ADC\",\n",
    "            (128 + 256 * 2, 25),\n",
    "            ha=\"center\",\n",
    "            va=\"center\",\n",
    "            fontsize=32,\n",
    "            color=\"white\",\n",
    "        )\n",
    "        axs.annotate(\n",
    "            metrics_slices[0],\n",
    "            (128 + 256 * 1, 50),\n",
    "            ha=\"center\",\n",
    "            va=\"center\",\n",
    "            fontsize=24,\n",
    "            color=\"white\",\n",
    "        )\n",
    "        axs.annotate(\n",
    "            metrics_slices[1],\n",
    "            (128 + 256 * 1, 50 + 256),\n",
    "            ha=\"center\",\n",
    "            va=\"center\",\n",
    "            fontsize=24,\n",
    "            color=\"white\",\n",
    "        )\n",
    "        axs.annotate(\n",
    "            metrics_slices[2],\n",
    "            (128 + 256 * 1, 50 + 512),\n",
    "            ha=\"center\",\n",
    "            va=\"center\",\n",
    "            fontsize=24,\n",
    "            color=\"white\",\n",
    "        )\n",
    "        axs.axis(\"off\")\n",
    "        plt.savefig(\n",
    "            figures_dir / f\"{patient_id}.png\", bbox_inches=\"tight\", pad_inches=0\n",
    "        )\n",
    "        plt.close()\n",
    "\n",
    "        # Save the niftis.\n",
    "        shutil.copy(adc_path, niftis_dir)\n",
    "        shutil.copy(ncct_path, niftis_dir)\n",
    "        adc_fake_arr = tf.image.resize(adc_fake_arr, adc_arr.shape[:2]).numpy()\n",
    "        adc_fake_arr = min_max_back_normalization(adc_fake_arr, adc_min, adc_max)\n",
    "        adc_fake = nib.Nifti1Image(\n",
    "            adc_fake_arr.astype(np.float32), adc.affine, adc.header\n",
    "        )\n",
    "        nib.save(adc_fake, niftis_dir / f\"{patient_id}_adc_fake.nii.gz\")\n",
    "\n",
    "\n",
    "def compute_metrics_for_patients(\n",
    "    patients_dirs: List[Union[str, Path]],\n",
    "    experiment_ids: List[Union[str, int]],\n",
    "    results_dir: Union[str, Path] = \"results\",\n",
    "):  \n",
    "    metrics = [\"psnr\", \"ssim\", \"ssim_multiscale\"]\n",
    "    for experiment_id in experiment_ids:\n",
    "        experiment_dir = Path(\n",
    "            get_path_of_directory_with_id(experiment_id, results_dir=results_dir)\n",
    "        )\n",
    "        weights_dir = experiment_dir / \"weights\"\n",
    "        generator, discriminator = load_models(weights_dir, 1, \"sigmoid\")\n",
    "\n",
    "        metrics_dict = {\"patient_id\": [], \"slice_index\": [], \"num_lesion_pixels\": []}\n",
    "        metrics_dict = {**metrics_dict, **{metric: [] for metric in metrics}}\n",
    "        metrics_dict = {\n",
    "            **metrics_dict,\n",
    "            **{f\"{metric}_lesion\": [] for metric in metrics},\n",
    "        }\n",
    "        for patient_dir in tqdm(\n",
    "            patients_dirs, desc=f\"Predicting for patients of experiment {experiment_id}\"\n",
    "        ):\n",
    "            if isinstance(patient_dir, str):\n",
    "                patient_dir = Path(patient_dir)\n",
    "\n",
    "            patient_id = patient_dir.name\n",
    "            adc_path = patient_dir / f\"{patient_id}_adc.nii.gz\"\n",
    "            ncct_path = patient_dir / f\"{patient_id}_ncct.nii.gz\"\n",
    "            mask_path = patient_dir / f\"masks/{patient_id}_r1_mask.nii.gz\"\n",
    "\n",
    "            ncct = nib.load(ncct_path)\n",
    "            ncct_arr = ncct.get_fdata()\n",
    "            ncct_arr_win = window_image(ncct_arr, 40, 80)\n",
    "            ncct_min, ncct_max = np.min(ncct_arr), np.max(ncct_arr)\n",
    "            ncct_arr = min_max_normalization(ncct_arr)\n",
    "            ncct_arr_res = tf.image.resize(ncct_arr, [256, 256]).numpy()\n",
    "            ncct_arr_win = min_max_normalization(ncct_arr_win)\n",
    "            ncct_arr_win_res = tf.image.resize(ncct_arr_win, [256, 256]).numpy()\n",
    "\n",
    "            adc = nib.load(adc_path)\n",
    "            adc_arr = adc.get_fdata()\n",
    "            adc_min, adc_max = np.min(adc_arr), np.max(adc_arr)\n",
    "            adc_arr = min_max_normalization(adc_arr)\n",
    "            adc_arr_res = tf.image.resize(adc_arr, [256, 256]).numpy()\n",
    "\n",
    "            # Compute the fake image.\n",
    "            adc_fake_arr = generator.predict(\n",
    "                ncct_arr_res.transpose(2, 0, 1)[..., np.newaxis], verbose=0\n",
    "            )\n",
    "            adc_fake_arr = adc_fake_arr.transpose(1, 2, 0, 3)[..., 0]\n",
    "\n",
    "            # Compute metrics.\n",
    "            assert (\n",
    "                adc_arr_res.shape == adc_fake_arr.shape\n",
    "            ), \"Real and Fake ADC shapes do not match.\"\n",
    "\n",
    "            if mask_path.exists():\n",
    "                mask = nib.load(mask_path)\n",
    "                mask_arr = mask.get_fdata()\n",
    "                mask_arr_res = tf.image.resize(\n",
    "                    mask_arr, [256, 256], method=\"nearest\"\n",
    "                ).numpy()\n",
    "\n",
    "            for i in range(adc_fake_arr.shape[-1]):\n",
    "                slice_metrics = compute_metrics(\n",
    "                    adc_arr_res[..., i : i + 1], adc_fake_arr[..., i : i + 1]\n",
    "                )\n",
    "                metrics_dict[\"patient_id\"].append(patient_id)\n",
    "                metrics_dict[\"slice_index\"].append(i)\n",
    "                if mask_path.exists():\n",
    "                    metrics_dict[\"num_lesion_pixels\"].append(\n",
    "                        np.count_nonzero(mask_arr_res[..., i : i + 1])\n",
    "                    )\n",
    "                else:\n",
    "                    metrics_dict[\"num_lesion_pixels\"].append(0)\n",
    "                for metric in metrics:\n",
    "                    metrics_dict[metric].append(slice_metrics[metric])\n",
    "                    metrics_dict[f\"{metric}_lesion\"].append(slice_metrics[metric])\n",
    "\n",
    "        pd.DataFrame(metrics_dict).to_csv(\n",
    "            str(experiment_dir / \"evaluation/test_metrics.csv\"), index=False\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compute metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'train_026': 45,\n",
       " 'train_035': 45,\n",
       " 'train_044': 99,\n",
       " 'train_058': 104,\n",
       " 'test_022': 69,\n",
       " 'test_037': 10}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv(\"/home/sangohe/projects/lesion-aware-translation/examples/examples_desc.csv\")[[\"patient_id\", \"slice_index\"]].set_index(\"patient_id\").transpose().to_dict()\n",
    "\n",
    "{\n",
    "    'train_026': 45,\n",
    "    'train_035': 45,\n",
    "    'train_044': 99,\n",
    "    'train_058': 104,\n",
    "    'test_022': 69,\n",
    "    'test_037': 10\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-24 19:31:57.902935: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:266] failed call to cuInit: CUDA_ERROR_INVALID_DEVICE: invalid device ordinal\n",
      "2023-07-24 19:31:57.903003: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:168] retrieving CUDA diagnostic information for host: 1660b6c49a51\n",
      "2023-07-24 19:31:57.903019: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:175] hostname: 1660b6c49a51\n",
      "2023-07-24 19:31:57.903132: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:199] libcuda reported version is: NOT_FOUND: was unable to find libcuda.so DSO loaded into this program\n",
      "2023-07-24 19:31:57.903177: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:203] kernel reported version is: 525.105.17\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "93e4f26a666a44b89fb7505b0a8d3b6a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting for patients of experiment 7:   0%|          | 0/38 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ae2ac202aede422d92630f01950398fb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting for patients of experiment 8:   0%|          | 0/38 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "patients_txt = \"/home/sangohe/projects/lesion-aware-translation/data/APIS_synth-1_0_3_0_10_0_shuffled/test_patients.txt\"\n",
    "patients_dirs = [Path(line.strip()) for line in open(patients_txt, \"r\").readlines()]\n",
    "\n",
    "results_dir = \"/home/sangohe/projects/lesion-aware-translation/results\"\n",
    "experiment_ids = [7, 8]  # 2 -> dilated weights\n",
    "\n",
    "compute_metrics_for_patients(patients_dirs, experiment_ids, results_dir)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create figures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_dir = \"/home/sangohe/projects/lesion-aware-translation/results\"\n",
    "experiment_ids = [7, 8]\n",
    "for experiment_id in experiment_ids:\n",
    "    experiment_dir = Path(get_path_of_directory_with_id(experiment_id, results_dir=results_dir))\n",
    "    weights_dir = experiment_dir / \"weights\"\n",
    "    generator, discriminator = load_models(weights_dir, 1, \"sigmoid\")\n",
    "    save_translations(experiment_dir / \"evaluation\", generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_dir = \"/home/sangohe/projects/lesion-aware-translation/results\"\n",
    "experiment_ids = [2] # 2 -> dilated weights\n",
    "for experiment_id in experiment_ids:\n",
    "    experiment_dir = Path(get_path_of_directory_with_id(experiment_id, results_dir=results_dir))\n",
    "    weights_dir = experiment_dir / \"weights\"\n",
    "    generator, discriminator = load_models(weights_dir, 1, \"sigmoid\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Todos\n",
    "\n",
    "- [ ] create a plot with the validation samples\n",
    "- [ ] compute the psnr and ssim for the test samples (and test patches)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read the images from different evaluation folders and plot them side by side"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_dir = \"/home/sangohe/projects/lesion-aware-translation/results\"\n",
    "experiment_ids = [7, 8]\n",
    "patient_ids = [\"train_026\", \"train_035\", \"train_044\", \"train_058\"]\n",
    "\n",
    "comparison_plots = []\n",
    "for patient_id in patient_ids:\n",
    "    figures = []\n",
    "    for experiment_id in experiment_ids:\n",
    "        experiment_dir = Path(get_path_of_directory_with_id(experiment_id, results_dir=results_dir))\n",
    "        figures_dir = experiment_dir / \"evaluation\" / \"figures\"\n",
    "        figure = cv2.imread(str(figures_dir / f\"{patient_id}.png\"))\n",
    "        figure = cv2.cvtColor(figure, cv2.COLOR_BGR2RGB)\n",
    "        figure = np.vstack([np.zeros((100, figure.shape[1], 3)).astype(np.uint8), figure])\n",
    "        figures.append(figure)\n",
    "        figures.append(np.ones((figure.shape[0], 10, 3)).astype(np.uint8) * 255)\n",
    "    figures.pop()\n",
    "    comparison_plots.append(np.hstack(figures))\n",
    "\n",
    "figures_dir = Path(\"/home/sangohe/projects/lesion-aware-translation/figures\")\n",
    "for i, (experiment_id, patient_id, comparison_plot) in enumerate(zip(experiment_ids, patient_ids, comparison_plots)):\n",
    "    plt.imshow(comparison_plot)\n",
    "    annotation = experiment_dir.name.split(\"-\")[3]\n",
    "    annotation = \"normal\" if not \"weights\" in annotation else annotation\n",
    "    plt.annotate(\"Weights\", (256*3, 45), ha=\"center\", va=\"center\", color=\"white\", fontsize=5)\n",
    "    plt.annotate(\"Dilated Weights\", (256*9, 45), ha=\"center\", va=\"center\", color=\"white\", fontsize=5)\n",
    "    plt.annotate(\"None\", (256*15, 45), ha=\"center\", va=\"center\", color=\"white\", fontsize=5)\n",
    "    plt.axis(\"off\")\n",
    "    plt.savefig(figures_dir / f\"{patient_id}_models_comparison_new.png\", bbox_inches=\"tight\", pad_inches=0, dpi=500)\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ WARN:0@2372.208] global loadsave.cpp:244 findDecoder imread_('/home/sangohe/projects/lesion-aware-translation/figures/train_026_models_comparison.png'): can't open/read file: check file path/integrity\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "all the input arrays must have same number of dimensions, but the array at index 0 has 2 dimension(s) and the array at index 1 has 3 dimension(s)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 9\u001b[0m\n\u001b[1;32m      6\u001b[0m figure \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mimread(\u001b[38;5;28mstr\u001b[39m(figure_path))\n\u001b[1;32m      7\u001b[0m figure_new \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mimread(\u001b[38;5;28mstr\u001b[39m(figure_path_new))\n\u001b[0;32m----> 9\u001b[0m new_figure \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvstack\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mfigure\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mones\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfigure_new\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m255\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mastype\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43muint8\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfigure_new\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     10\u001b[0m cv2\u001b[38;5;241m.\u001b[39mimwrite(\u001b[38;5;28mstr\u001b[39m(figures_dir \u001b[38;5;241m/\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpatient_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_full_comparison.png\u001b[39m\u001b[38;5;124m\"\u001b[39m), new_figure)\n",
      "File \u001b[0;32m<__array_function__ internals>:180\u001b[0m, in \u001b[0;36mvstack\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/numpy/core/shape_base.py:282\u001b[0m, in \u001b[0;36mvstack\u001b[0;34m(tup)\u001b[0m\n\u001b[1;32m    280\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(arrs, \u001b[38;5;28mlist\u001b[39m):\n\u001b[1;32m    281\u001b[0m     arrs \u001b[38;5;241m=\u001b[39m [arrs]\n\u001b[0;32m--> 282\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_nx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconcatenate\u001b[49m\u001b[43m(\u001b[49m\u001b[43marrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m<__array_function__ internals>:180\u001b[0m, in \u001b[0;36mconcatenate\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: all the input arrays must have same number of dimensions, but the array at index 0 has 2 dimension(s) and the array at index 1 has 3 dimension(s)"
     ]
    }
   ],
   "source": [
    "figures_dir = Path(\"/home/sangohe/projects/lesion-aware-translation/figures\")\n",
    "\n",
    "for patient_id in patient_ids[:-1]:\n",
    "    figure_path = figures_dir / f\"{patient_id}_models_comparison.png\"\n",
    "    figure_path_new = figures_dir / f\"{patient_id}_models_comparison_new.png\"\n",
    "    figure = cv2.imread(str(figure_path))\n",
    "    figure_new = cv2.imread(str(figure_path_new))\n",
    "\n",
    "    new_figure = np.vstack([figure, (np.ones((5, figure_new.shape[1], 3)) * 255).astype(np.uint8), figure_new])\n",
    "    cv2.imwrite(str(figures_dir / f\"{patient_id}_full_comparison.png\"), new_figure)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 2480)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.ones((100, figure_new.shape[1])).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
